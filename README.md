# SpikeAgent

## Overview  
SpikeAgent is a multimodal large language model (LLM)-based AI agent that automates and standardizes the spike sorting pipeline, a critical process in neural signal decoding. Traditional workflows are fragmented, labor-intensive, and require expert curation, limiting scalability and reproducibility. SpikeAgent overcomes these challenges by leveraging LLMs for autonomous decision-making, reasoning, and interaction with intermediate results.  

## Features  
- **End-to-End Automation** – Handles preprocessing, spike detection, feature extraction, clustering, and validation.  
- **Multimodal Interaction** – Supports text, voice, and image-based inputs.  
- **Autonomous Reasoning** – Uses LLMs and coding functions to optimize sorting without human intervention.  
- **Interpretable Results** – Generates detailed reports explaining sorting decisions.  
- **High Efficiency** – Reduces curation time from 40+ minutes to just a few minutes per 100 spikes.  
- **Benchmark-Validated** – Matches or surpasses expert-level curation across various spike-sorting algorithms and electrode types.  

## Demo
<video src="https://github.com/LiuLab-Bioelectronics-Harvard/spike_agent/assets/spike_sorting_AI_agent_demo.mp4"></video>

## Getting Started

1. Clone the repository
   ```bash
   git clone https://github.com/LiuLab-Bioelectronics-Harvard/spike_agent.git
   cd spike_agent
   ```

2. Install the dependencies

   We use conda to manage the dependencies and currently only support the Linux system.

   ### Linux Users

   ```bash
   # Create the environment from the file
   conda env create -f environment.linux.yml
   
   # Activate the environment
   conda activate spike_agent
   ```


3. Set up your environment variables
   - Create a `.env` file in the root directory
   - Add your API key in this file. The API keys needed for this agent are:
    ```
    # If you want to use OpenAI models, you need to add the following:
    OPENAI_API_KEY=your-api-key-here
    OPENAI_API_BASE=your-api-base-here
    WHISPER_API_KEY=your-whisper-api-key-here

    # If you want to use Claude, you need to add the following:
    ANTHROPIC_API_KEY=your-anthropic-api-key-here

    # If you want to use Gemini, you need to add the following:
    GOOGLE_API_KEY=your-google-api-key-here
    ```

4. (Optional) Modify the default parameters in `src/Agent/default.py`
   - Set the `raw_data_path` to the path of your raw data.
   - Set the `processed_path` to the path of your processed data.
   - Set the `folder_name` to the data directory name under your raw data path.
    
    You may also directly share parameters with the agent and our agent will set them for you. 

5. Run the app
   ```bash
   streamlit run src/unified_app.py
   ```

The app will open in your default web browser at the local host.

## Usage
1. `src`: this directory contains the source code of the spike sorting agent.
2. `data`: this directory can be used to hold the data for the spike sorting. It also contains an example dataset in `raw_data/0330`. You can unzip the data files and testing with our agent.
3. `src/tmp/plots`: this directory contains the plots generated by the agent.
4. `conversation_histories_{model}`: these directories contains the conversation history of the agent classfied by the model used. You may load and save the conversation history with the agent.
